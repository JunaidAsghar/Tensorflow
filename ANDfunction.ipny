"""
A simple Neural network/Model learning the AND function with one hidden layer in Tensorflow 
"""
import tensorflow as tf

# Data Dimenshions
hidden_nodes_l1 = 30

# Trainig Data for AND function:
x_train = [[0, 0], [0, 1], [1, 0], [1, 1]] # input
# y_train=[0,      0,      0,      1]   # output =>
y_true=[[1,0],  [1,0],  [1,0], [0,1]] # ONE HOT EN-CODING REPRESENTATION! 'class' [1,0]==0 [0,1]==1

# Initializing Placeholders x and y_ for input and output data
x = tf.placeholder("float", [None,2])
y_ = tf.placeholder("float", [None, 2]) # two output classes

# First layer.
# initializign weights 
weights_l1 = tf.Variable(tf.random_uniform([2, hidden_nodes_l1], -.01, .01))

#initializing biases
biases_l1 = tf.Variable(tf.random_uniform([hidden_nodes_l1], -.01, .01))
layer_1  = tf.nn.relu(tf.matmul(x,weights_l1) + biases_l1) 

# Output Layer
# initializign weights 
weights_out = tf.Variable(tf.random_uniform([hidden_nodes_l1,2], -.1, .1))

#initializing biases
biases_out = tf.Variable(tf.zeros([2]))
logits = tf.matmul(layer_1, weights_out) + biases_out

y = tf.nn.softmax(logits)
# Define loss and optimizer
cross_entropy = -tf.reduce_sum(y_*tf.log(y))
train_step = tf.train.GradientDescentOptimizer(0.2).minimize(cross_entropy)

# Training the model

# Initializing tensorflw Session
sess = tf.InteractiveSession()

#Initializing the global variables
init = tf.global_variables_initializer()
sess.run(init)

for epoch in range(1000):
    # feed the net with Trainig inputs and true ouptput class.
    # Creaating the Feed_dict 
    feed_dict={x: x_train, y_:y_true } 
    loss,opt=sess.run([cross_entropy,train_step],feed_dict)
    if loss<1:break # early stopping
    print ("Epoch %d : LOSS %s" %(epoch,loss)) # loss should decrease over time)


# Testing  the trained model by checkong the accuracy
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_true,1)) # argmax along dim-1
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float")) # [True, False, True, True] -> [1,0,1,1] -> 0.75.

print ("accuracy %s" % (accuracy.eval({x: x_train, y_: y_true})))

# Check the results on the trained model by passing new data
output = tf.argmax(y,1) 
print ( output.eval({x: x_train}))
